# ğŸ“Š Product Backlog Detalhado - justiceai

**VersÃ£o**: 1.0
**Data**: 2026-02-08
**Formato**: User Stories com critÃ©rios INVEST

---

## ğŸ“Œ Legenda

**Prioridade**:
- ğŸ”´ **CRITICAL**: Bloqueante, MVP depende
- ğŸŸ  **HIGH**: Importante para MVP
- ğŸŸ¡ **MEDIUM**: DesejÃ¡vel para v1.0
- ğŸŸ¢ **LOW**: Nice to have, v1.x

**Estimativa**: Story Points (Fibonacci: 1, 2, 3, 5, 8, 13, 21)

**Status**:
- â³ **TODO**: NÃ£o iniciada
- ğŸ—ï¸ **IN PROGRESS**: Em desenvolvimento
- âœ… **DONE**: Completada e aceita
- âŒ **BLOCKED**: Bloqueada por dependÃªncia

---

## ğŸ¯ Ã‰PICO 1: Setup & FundaÃ§Ã£o

### US-001: Setup Projeto com Poetry ğŸ”´
**Prioridade**: CRITICAL
**Estimativa**: 3 SP
**Sprint**: Sprint 0
**Status**: â³ TODO

**User Story**:
> Como **desenvolvedor**,
> Eu quero um **projeto Python estruturado com Poetry**,
> Para **gerenciar dependÃªncias de forma profissional**

**CritÃ©rios de Aceite**:
```gherkin
Feature: Setup Projeto com Poetry

Scenario: Projeto Ã© instalÃ¡vel
  Given repositÃ³rio clonado
  When executar "poetry install"
  Then todas dependÃªncias devem ser instaladas
  And ambiente virtual deve ser criado

Scenario: Estrutura de diretÃ³rios
  Given projeto instalado
  Then deve existir diretÃ³rio "justiceai/"
  And deve existir diretÃ³rio "tests/"
  And deve existir "pyproject.toml"
  And deve existir "README.md"

Scenario: Import bÃ¡sico funciona
  Given projeto instalado
  When executar "python -c 'import justiceai'"
  Then nÃ£o deve haver erros
  And deve exibir versÃ£o correta
```

**Tasks TÃ©cnicas**:
- [ ] Instalar Poetry (>= 1.7.0)
- [ ] Executar `poetry init --name justiceai`
- [ ] Configurar `pyproject.toml` completo
- [ ] Adicionar dependÃªncias core: numpy, pandas, scikit-learn, scipy
- [ ] Adicionar dependÃªncias de visualizaÃ§Ã£o: plotly, jinja2
- [ ] Adicionar dependÃªncias de dev: pytest, black, mypy, ruff
- [ ] Criar estrutura: `justiceai/`, `tests/`, `examples/`, `docs/`
- [ ] Criar `justiceai/__init__.py` com `__version__ = "0.1.0"`
- [ ] Inicializar Git: `git init`
- [ ] Criar `.gitignore` (Python template)
- [ ] Testar `poetry install` e `poetry shell`

**DependÃªncias**: Nenhuma

**ReferÃªncias**:
- Guia: `/home/guhaase/projetos/DeepBridge/desenvolvimento/GUIA_BUILD_PUBLICACAO_PYTHON.md`
- Template: DeepBridge `pyproject.toml`

**Definition of Done (DoD)**:
- [x] CÃ³digo: `poetry install` funciona sem erros
- [x] Estrutura de diretÃ³rios criada
- [x] `import justiceai` funciona
- [x] Git inicializado com commit inicial
- [x] PR criado e aprovado
- [x] Documentado em README

---

### US-002: CI/CD com GitHub Actions ğŸ”´
**Prioridade**: CRITICAL
**Estimativa**: 5 SP
**Sprint**: Sprint 0
**Status**: â³ TODO

**User Story**:
> Como **desenvolvedor**,
> Eu quero **pipeline CI/CD automatizado**,
> Para **garantir qualidade em cada commit**

**CritÃ©rios de Aceite**:
```gherkin
Feature: CI/CD Pipeline

Scenario: Workflow de testes funciona
  Given cÃ³digo commitado
  When push para branch main
  Then workflow "test.yml" deve executar
  And testes devem passar em Python 3.10, 3.11, 3.12
  And coverage report deve ser gerado

Scenario: Workflow de qualidade funciona
  Given cÃ³digo commitado
  When criar Pull Request
  Then workflow "quality.yml" deve executar
  And black/isort devem validar formataÃ§Ã£o
  And mypy deve validar tipos
  And ruff deve validar linting

Scenario: Badges no README
  Given workflows configurados
  When acessar README.md
  Then deve exibir badge "build: passing"
  And deve exibir badge "coverage: XX%"
  And deve exibir badge "python: 3.10 | 3.11 | 3.12"
```

**Tasks TÃ©cnicas**:
- [ ] Criar `.github/workflows/test.yml`
  - [ ] Matrix: Python 3.10, 3.11, 3.12
  - [ ] Matrix: OS ubuntu-latest, macos-latest, windows-latest
  - [ ] Rodar `pytest --cov`
  - [ ] Upload para Codecov
- [ ] Criar `.github/workflows/quality.yml`
  - [ ] Check: Black formataÃ§Ã£o
  - [ ] Check: isort imports
  - [ ] Check: MyPy types
  - [ ] Check: Ruff linting
  - [ ] Fail se qualquer check falhar
- [ ] Criar `.github/workflows/build.yml`
  - [ ] Build wheel e sdist
  - [ ] Validar com twine check
  - [ ] Upload artifacts
- [ ] Configurar Codecov
  - [ ] Criar conta em codecov.io
  - [ ] Adicionar token em GitHub Secrets
  - [ ] Configurar `codecov.yml`
- [ ] Adicionar badges ao README.md
  - [ ] Build status
  - [ ] Coverage
  - [ ] Python versions
  - [ ] License
  - [ ] PyPI version (placeholder)

**DependÃªncias**: US-001 (projeto criado)

**ReferÃªncias**:
- Template: DeepBridge `.github/workflows/`
- Docs: https://docs.github.com/actions

**DoD**:
- [x] Workflows executam em cada PR
- [x] Testes passam em 3 versÃµes Python
- [x] Coverage > 80% (inicial)
- [x] Badges funcionando no README
- [x] CI documentado em CONTRIBUTING.md

---

### US-003: Configurar Linters e Formatters ğŸ”´
**Prioridade**: CRITICAL
**Estimativa**: 3 SP
**Sprint**: Sprint 0
**Status**: â³ TODO

**User Story**:
> Como **desenvolvedor**,
> Eu quero **ferramentas de qualidade configuradas**,
> Para **manter cÃ³digo consistente e limpo**

**CritÃ©rios de Aceite**:
```gherkin
Feature: Linters e Formatters

Scenario: Black formata cÃ³digo
  Given arquivo Python desformatado
  When executar "make format"
  Then cÃ³digo deve ser formatado (line-length=88)
  And deve seguir estilo Black

Scenario: MyPy valida tipos
  Given cÃ³digo com type hints
  When executar "make type-check"
  Then MyPy deve validar sem erros
  And strict mode deve estar ativo

Scenario: Ruff valida linting
  Given cÃ³digo formatado
  When executar "make lint"
  Then Ruff deve validar sem warnings
  And deve checar: E, W, F, I, B, C4, UP, ARG, SIM

Scenario: Pre-commit hooks funcionam
  Given hooks instalados
  When tentar commitar cÃ³digo ruim
  Then commit deve ser bloqueado
  And deve sugerir correÃ§Ãµes
```

**Tasks TÃ©cnicas**:
- [ ] Configurar Black em `pyproject.toml`:
  ```toml
  [tool.black]
  line-length = 88
  target-version = ['py310', 'py311', 'py312']
  ```
- [ ] Configurar isort:
  ```toml
  [tool.isort]
  profile = "black"
  line_length = 88
  ```
- [ ] Configurar MyPy (strict):
  ```toml
  [tool.mypy]
  strict = true
  python_version = "3.10"
  ```
- [ ] Configurar Ruff:
  ```toml
  [tool.ruff]
  line-length = 88
  select = ["E", "W", "F", "I", "B", "C4", "UP", "ARG", "SIM"]
  ```
- [ ] Configurar Pylint:
  ```toml
  [tool.pylint.main]
  py-version = "3.10"
  ```
- [ ] Criar `.pre-commit-config.yaml`:
  - [ ] Hook: trailing-whitespace
  - [ ] Hook: end-of-file-fixer
  - [ ] Hook: black
  - [ ] Hook: isort
  - [ ] Hook: ruff
  - [ ] Hook: mypy
- [ ] Criar `Makefile`:
  - [ ] Target: `make format` (black + isort)
  - [ ] Target: `make lint` (ruff + pylint)
  - [ ] Target: `make type-check` (mypy)
  - [ ] Target: `make test` (pytest)
  - [ ] Target: `make quality` (all above)
- [ ] Instalar hooks: `pre-commit install`
- [ ] Rodar em codebase: `make quality`

**DependÃªncias**: US-001

**ReferÃªncias**:
- Guia: `GUIA_QUALIDADE_CODIGO_PYTHON.md`

**DoD**:
- [x] Todas configs em `pyproject.toml`
- [x] Pre-commit hooks instalados
- [x] `make quality` passa sem erros
- [x] Documentado em README

---

### US-004: Setup de Testes com Pytest ğŸ”´
**Prioridade**: CRITICAL
**Estimativa**: 3 SP
**Sprint**: Sprint 0
**Status**: â³ TODO

**User Story**:
> Como **desenvolvedor**,
> Eu quero **framework de testes configurado**,
> Para **escrever testes desde o inÃ­cio**

**CritÃ©rios de Aceite**:
```gherkin
Feature: Framework de Testes

Scenario: Pytest executa testes
  Given testes escritos em tests/
  When executar "pytest"
  Then todos testes devem executar
  And deve exibir sumÃ¡rio

Scenario: Coverage Ã© calculado
  Given testes executados
  When executar "pytest --cov"
  Then deve gerar relatÃ³rio de coverage
  And deve mostrar linhas nÃ£o cobertas
  And deve gerar HTML em htmlcov/

Scenario: Fixtures bÃ¡sicos disponÃ­veis
  Given arquivo tests/conftest.py
  Then deve ter fixture "sample_data"
  And deve ter fixture "sample_model"
  And deve ter fixture "sample_predictions"
```

**Tasks TÃ©cnicas**:
- [ ] Adicionar pytest dependencies:
  ```toml
  pytest>=7.0
  pytest-cov>=4.0
  pytest-xdist>=3.0
  ```
- [ ] Configurar pytest em `pyproject.toml`:
  ```toml
  [tool.pytest.ini_options]
  testpaths = ["tests"]
  python_files = ["test_*.py"]
  addopts = "--cov=justiceai --cov-report=term-missing --cov-report=html"
  ```
- [ ] Configurar coverage:
  ```toml
  [tool.coverage.run]
  source = ["justiceai"]
  omit = ["*/tests/*"]
  branch = true

  [tool.coverage.report]
  precision = 2
  show_missing = true
  fail_under = 90
  ```
- [ ] Criar estrutura `tests/`:
  ```
  tests/
  â”œâ”€â”€ __init__.py
  â”œâ”€â”€ conftest.py          # Fixtures globais
  â”œâ”€â”€ core/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â””â”€â”€ metrics/
  â”‚       â””â”€â”€ test_pretrain.py
  â””â”€â”€ test_api.py
  ```
- [ ] Criar `tests/conftest.py` com fixtures:
  ```python
  @pytest.fixture
  def sample_data():
      return pd.DataFrame(...)

  @pytest.fixture
  def sample_model():
      return RandomForestClassifier()
  ```
- [ ] Criar teste dummy que passa:
  ```python
  def test_import():
      import justiceai
      assert justiceai.__version__ == "0.1.0"
  ```
- [ ] Adicionar ao Makefile:
  ```makefile
  test:
      pytest

  test-cov:
      pytest --cov --cov-report=html
      open htmlcov/index.html  # macOS
  ```
- [ ] Documentar em CONTRIBUTING.md

**DependÃªncias**: US-001

**DoD**:
- [x] `pytest` executa sem erros
- [x] Coverage configurado (target 90%)
- [x] Fixtures bÃ¡sicos criados
- [x] Pelo menos 1 teste passando
- [x] Documentado como rodar testes

---

### US-005: DocumentaÃ§Ã£o Inicial ğŸŸ 
**Prioridade**: HIGH
**Estimativa**: 5 SP
**Sprint**: Sprint 0
**Status**: â³ TODO

**User Story**:
> Como **usuÃ¡rio potencial**,
> Eu quero **documentaÃ§Ã£o clara do projeto**,
> Para **entender o que Ã© e como usar**

**CritÃ©rios de Aceite**:
```gherkin
Feature: DocumentaÃ§Ã£o Inicial

Scenario: README completo
  Given acesso ao repositÃ³rio
  When abrir README.md
  Then deve ter descriÃ§Ã£o clara do projeto
  And deve ter badges (build, coverage, etc.)
  And deve ter Quick Start com exemplo
  And deve ter instruÃ§Ãµes de instalaÃ§Ã£o
  And deve ter seÃ§Ã£o "Contributing"
  And deve ter link para documentaÃ§Ã£o completa

Scenario: LICENSE presente
  Given repositÃ³rio pÃºblico
  When verificar root directory
  Then deve existir arquivo LICENSE
  And deve ser MIT License

Scenario: CHANGELOG iniciado
  Given projeto versionado
  When verificar CHANGELOG.md
  Then deve seguir formato Keep a Changelog
  And deve ter seÃ§Ã£o [Unreleased]
  And deve ter seÃ§Ã£o [0.1.0]
```

**Tasks TÃ©cnicas**:
- [ ] Escrever `README.md`:
  ```markdown
  # justiceai

  [![Build](https://github.com/.../badge.svg)]()
  [![Coverage](https://codecov.io/.../badge.svg)]()
  [![Python](https://img.shields.io/badge/python-3.10%2B-blue)]()
  [![License](https://img.shields.io/badge/license-MIT-green)]()

  > Biblioteca Python para anÃ¡lise de fairness em ML

  ## ğŸš€ Quick Start

  ```python
  from justiceai import audit

  report = audit(model, data, protected_attrs=['gender'])
  report.show()  # Abre HTML no navegador
  ```

  ## ğŸ“¦ InstalaÃ§Ã£o

  ```bash
  pip install justiceai  # Em breve!
  ```

  ## ğŸ¯ Features

  - 15+ mÃ©tricas de fairness
  - Reports HTML interativos
  - Compliance LGPD/BACEN
  - Framework-agnostic

  ## ğŸ“š DocumentaÃ§Ã£o

  https://justiceai.readthedocs.io (em breve)

  ## ğŸ¤ Contributing

  Veja [CONTRIBUTING.md](CONTRIBUTING.md)

  ## ğŸ“„ LicenÃ§a

  MIT License - veja [LICENSE](LICENSE)
  ```
- [ ] Criar `LICENSE` (MIT):
  ```
  MIT License

  Copyright (c) 2026 Gustavo Haase
  ...
  ```
- [ ] Criar `CHANGELOG.md`:
  ```markdown
  # Changelog

  ## [Unreleased]

  ### Added
  - Projeto inicial
  - Setup com Poetry
  - CI/CD com GitHub Actions

  ## [0.1.0] - 2026-02-XX

  ### Added
  - Primeira release
  ```
- [ ] Criar `CONTRIBUTING.md`:
  ```markdown
  # Contribuindo para justiceai

  ## Desenvolvimento

  1. Fork e clone
  2. `poetry install`
  3. Criar branch: `git checkout -b feature/nova-feature`
  4. Fazer mudanÃ§as
  5. Rodar testes: `make test`
  6. Rodar qualidade: `make quality`
  7. Commit: `git commit -m "feat: adiciona nova feature"`
  8. Push e abrir PR

  ## Code of Conduct

  Seja respeitoso e profissional.

  ## Reportar Bugs

  Abra issue com template.
  ```
- [ ] Criar `.github/ISSUE_TEMPLATE/bug_report.md`
- [ ] Criar `.github/ISSUE_TEMPLATE/feature_request.md`
- [ ] Criar `.github/PULL_REQUEST_TEMPLATE.md`

**DependÃªncias**: US-001

**DoD**:
- [x] README completo e renderiza bem
- [x] LICENSE presente (MIT)
- [x] CHANGELOG.md criado
- [x] CONTRIBUTING.md criado
- [x] Templates de issue/PR criados

---

### US-006: Estrutura de MÃ³dulos Base ğŸ”´
**Prioridade**: CRITICAL
**Estimativa**: 2 SP
**Sprint**: Sprint 0
**Status**: â³ TODO

**User Story**:
> Como **desenvolvedor**,
> Eu quero **estrutura de mÃ³dulos criada**,
> Para **comeÃ§ar implementaÃ§Ã£o organizada**

**CritÃ©rios de Aceite**:
```gherkin
Feature: Estrutura de MÃ³dulos

Scenario: Imports bÃ¡sicos funcionam
  Given projeto instalado
  When executar "import justiceai"
  Then deve importar sem erros
  And deve ter __version__ definido

Scenario: MÃ³dulos core existem
  Given estrutura criada
  Then deve existir justiceai/core/
  And deve existir justiceai/core/metrics/
  And deve existir justiceai/core/evaluators/
  And deve existir justiceai/core/adapters/

Scenario: Todos mÃ³dulos sÃ£o importÃ¡veis
  Given estrutura criada
  When tentar importar cada mÃ³dulo
  Then nenhum deve dar erro
```

**Tasks TÃ©cnicas**:
- [ ] Criar estrutura completa:
  ```
  justiceai/
  â”œâ”€â”€ __init__.py           # Version, exports
  â”œâ”€â”€ api.py                # High-level audit() function
  â”œâ”€â”€ core/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ metrics/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ pretrain.py   # Pre-training metrics
  â”‚   â”‚   â”œâ”€â”€ posttrain.py  # Post-training metrics
  â”‚   â”‚   â””â”€â”€ calculator.py # FairnessCalculator
  â”‚   â”œâ”€â”€ evaluators/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ fairness.py   # FairnessEvaluator
  â”‚   â”‚   â””â”€â”€ threshold.py  # ThresholdAnalyzer
  â”‚   â””â”€â”€ adapters/
  â”‚       â”œâ”€â”€ __init__.py
  â”‚       â”œâ”€â”€ base.py       # BaseAdapter (ABC)
  â”‚       â”œâ”€â”€ sklearn.py
  â”‚       â””â”€â”€ xgboost.py
  â”œâ”€â”€ reports/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ transformers/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â””â”€â”€ data_transformer.py
  â”‚   â”œâ”€â”€ renderers/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â””â”€â”€ html_renderer.py
  â”‚   â”œâ”€â”€ templates/
  â”‚   â”‚   â””â”€â”€ fairness_report.html
  â”‚   â””â”€â”€ report_builder.py
  â”œâ”€â”€ compliance/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ lgpd.py
  â”‚   â””â”€â”€ bacen.py
  â”œâ”€â”€ monitoring/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ drift.py
  â”‚   â””â”€â”€ alerting.py
  â””â”€â”€ utils/
      â”œâ”€â”€ __init__.py
      â”œâ”€â”€ validators.py
      â””â”€â”€ helpers.py
  ```
- [ ] Criar `justiceai/__init__.py`:
  ```python
  """
  justiceai - Fairness Analysis for ML in Production

  A Python library for fairness analysis in machine learning,
  focused on production monitoring and Brazilian compliance (LGPD/BACEN).
  """

  __version__ = "0.1.0"
  __author__ = "Gustavo Haase"
  __email__ = "gustavo.haase@gmail.com"
  __license__ = "MIT"

  # High-level API
  from justiceai.api import audit

  __all__ = ["audit"]
  ```
- [ ] Criar todos `__init__.py` vazios nos mÃ³dulos
- [ ] Criar arquivos `.py` com docstrings e `pass`:
  ```python
  """
  Module: pretrain.py
  Pre-training fairness metrics (model-independent).
  """

  # Implementation coming in Sprint 1
  ```
- [ ] Adicionar type: ignore temporÃ¡rios para MyPy
- [ ] Criar teste de import:
  ```python
  def test_import_justiceai():
      import justiceai
      assert justiceai.__version__ == "0.1.0"

  def test_import_submodules():
      from justiceai.core.metrics import pretrain
      from justiceai.reports import report_builder
      # etc
  ```

**DependÃªncias**: US-001, US-004

**DoD**:
- [x] Estrutura completa criada
- [x] Todos `__init__.py` presentes
- [x] `import justiceai` funciona
- [x] Testes de import passam
- [x] MyPy passa (com ignores temporÃ¡rios OK)

---

## ğŸ¯ Ã‰PICO 2: MÃ©tricas Core

### US-007: MÃ©tricas Pre-Training ğŸ”´
**Ver PLANEJAMENTO_AGIL.md Sprint 1**

### US-008: MÃ©tricas Post-Training BÃ¡sicas ğŸ”´
**Ver PLANEJAMENTO_AGIL.md Sprint 1**

### US-009: MÃ©tricas Post-Training AvanÃ§adas ğŸ”´
**Ver PLANEJAMENTO_AGIL.md Sprint 1**

... [continua com todas as outras user stories]

---

## ğŸ“Š Backlog Summary

| Ã‰pico | Stories | Total SP | Status |
|-------|---------|----------|--------|
| E1: Setup & FundaÃ§Ã£o | 6 | 21 SP | â³ TODO |
| E2: MÃ©tricas Core | 6 | 66 SP | â³ TODO |
| E3: Reports HTML | 6 | 64 SP | â³ TODO |
| E4: API Simplificada | 6 | 70 SP | â³ TODO |
| E5: Compliance Brasil | 5 | 56 SP | â³ TODO |
| E6: Monitoring | - | - | â³ TODO |
| E7: Docs & Polish | - | - | â³ TODO |
| **TOTAL MVP** | **~35 stories** | **~280 SP** | â³ TODO |

**Velocity Estimada**: ~60 SP/sprint (2 devs Ã— 2 weeks Ã— 15 SP/dev/week)
**Sprints NecessÃ¡rias**: 5 sprints (280 SP / 60 SP/sprint â‰ˆ 4.7 sprints)

---

**Ãšltima AtualizaÃ§Ã£o**: 2026-02-08
**Mantido por**: Gustavo Haase
**Formato**: Agile User Stories (INVEST)
